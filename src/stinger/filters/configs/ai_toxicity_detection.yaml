# Phase 5a: AI-Based Toxicity Detection Filter Configuration
# This configuration uses OpenAI for high-accuracy toxicity detection with fallback to regex

filters:
  - name: "ai_toxicity_detection"
    type: "ai_toxicity_detection"
    enabled: true
    api_key: "${OPENAI_API_KEY}"
    confidence_threshold: 0.7
    on_error: "allow"

# Configuration Options:
# - api_key: OpenAI API key (can use environment variable ${OPENAI_API_KEY})
# - confidence_threshold: Minimum confidence to block content (0.0 to 1.0)
# - on_error: Action when AI fails (block, allow, warn) - defaults to allow with regex fallback
# 
# Note: This filter automatically falls back to simple regex detection if AI is unavailable
# Model is automatically configured from src/core/configs/models.yaml (uses gpt-4.1-nano) 